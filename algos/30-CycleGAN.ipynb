{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2009901198.py, line 116)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[2], line 116\u001B[0;36m\u001B[0m\n\u001B[0;31m    \u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "# 定义生成器\n",
    "def build_generator():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(256, 256, 3)))\n",
    "    model.add(layers.Conv2D(64, kernel_size=7, padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2D(256, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Conv2D(3, kernel_size=7, padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "# 定义判别器\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(256, 256, 3)))\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2D(512, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2D(1, kernel_size=4, padding='same'))\n",
    "    return model\n",
    "\n",
    "\n",
    "# 定义CycleGAN类\n",
    "class CycleGAN(keras.Model):\n",
    "    def __init__(self, generator_g, generator_f, discriminator_x, discriminator_y, lambda_cycle=10):\n",
    "        super(CycleGAN, self).__init__()\n",
    "        self.generator_g = generator_g\n",
    "        self.generator_f = generator_f\n",
    "        self.discriminator_x = discriminator_x\n",
    "        self.discriminator_y = discriminator_y\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "\n",
    "    def train_step(self, real_x, real_y):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            fake_y = self.generator_g(real_x)\n",
    "            cycled_x = self.generator_f(fake_y)\n",
    "\n",
    "            fake_x = self.generator_f(real_y)\n",
    "            cycled_y = self.generator_g(fake_x)\n",
    "\n",
    "            disc_real_x = self.discriminator_x(real_x)\n",
    "            disc_real_y = self.discriminator_y(real_y)\n",
    "\n",
    "            disc_fake_x = self.discriminator_x(fake_x)\n",
    "            disc_fake_y = self.discriminator_y(fake_y)\n",
    "\n",
    "            # 计算损失\n",
    "            loss_gen_g = keras.losses.binary_crossentropy(tf.ones_like(disc_fake_y), disc_fake_y)\n",
    "            loss_gen_f = keras.losses.binary_crossentropy(tf.ones_like(disc_fake_x), disc_fake_x)\n",
    "            loss_cycle_x = tf.reduce_mean(tf.abs(real_x - cycled_x))\n",
    "            loss_cycle_y = tf.reduce_mean(tf.abs(real_y - cycled_y))\n",
    "\n",
    "            total_gen_g = loss_gen_g + self.lambda_cycle * loss_cycle_x\n",
    "            total_gen_f = loss_gen_f + self.lambda_cycle * loss_cycle_y\n",
    "\n",
    "            loss_disc_x = keras.losses.binary_crossentropy(tf.ones_like(disc_real_x), disc_real_x) + \\\n",
    "                          keras.losses.binary_crossentropy(tf.zeros_like(disc_fake_x), disc_fake_x)\n",
    "\n",
    "            loss_disc_y = keras.losses.binary_crossentropy(tf.ones_like(disc_real_y), disc_real_y) + \\\n",
    "                          keras.losses.binary_crossentropy(tf.zeros_like(disc_fake_y), disc_fake_y)\n",
    "\n",
    "        # 计算梯度\n",
    "        grads_g = tape.gradient(total_gen_g, self.generator_g.trainable_variables)\n",
    "        grads_f = tape.gradient(total_gen_f, self.generator_f.trainable_variables)\n",
    "        grads_disc_x = tape.gradient(loss_disc_x, self.discriminator_x.trainable_variables)\n",
    "        grads_disc_y = tape.gradient(loss_disc_y, self.discriminator_y.trainable_variables)\n",
    "\n",
    "        # 更新权重\n",
    "        self.optimizer.apply_gradients(zip(grads_g, self.generator_g.trainable_variables))\n",
    "        self.optimizer.apply_gradients(zip(grads_f, self.generator_f.trainable_variables))\n",
    "        self.optimizer.apply_gradients(zip(grads_disc_x, self.discriminator_x.trainable_variables))\n",
    "        self.optimizer.apply_gradients(zip(grads_disc_y, self.discriminator_y.trainable_variables))\n",
    "\n",
    "        return {\n",
    "            \"g_loss\": total_gen_g,\n",
    "            \"f_loss\": total_gen_f,\n",
    "            \"d_x_loss\": loss_disc_x,\n",
    "            \"d_y_loss\": loss_disc_y,\n",
    "        }\n",
    "\n",
    "\n",
    "# 构建模型\n",
    "generator_g = build_generator()  # G: Horse -> Zebra\n",
    "generator_f = build_generator()  # F: Zebra -> Horse\n",
    "discriminator_x = build_discriminator()  # D_X\n",
    "discriminator_y = build_discriminator()  # D_Y\n",
    "\n",
    "cyclegan = CycleGAN(generator_g, generator_f, discriminator_x, discriminator_y)\n",
    "cyclegan.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# 加载Horse2Zebra数据集\n",
    "dataset, metadata = tfds.load('cycle_gan/horse2zebra', with_info=True, as_supervised=True)\n",
    "train_horses, train_zebras = dataset['trainA'], dataset['trainB']\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = (image / 127.5) - 1  # 归一化到[-1, 1]\n",
    "    return image\n",
    "\n",
    "\n",
    "train_horses = train_horses.map(preprocess_image).batch(1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-14T14:40:26.804922Z",
     "start_time": "2024-10-14T14:40:26.791265Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
